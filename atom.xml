<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Moment of Methods]]></title>
  <link href="http://momentofmethods.com/atom.xml" rel="self"/>
  <link href="http://momentofmethods.com/"/>
  <updated>2013-02-11T21:19:34+01:00</updated>
  <id>http://momentofmethods.com/</id>
  <author>
    <name><![CDATA[Miklós Koren]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[I like my coffee black, my whisky neat, and my text plain]]></title>
    <link href="http://momentofmethods.com/blog/2013/02/11/i-like-my-coffee-black/"/>
    <updated>2013-02-11T13:35:00+01:00</updated>
    <id>http://momentofmethods.com/blog/2013/02/11/i-like-my-coffee-black</id>
    <content type="html"><![CDATA[<p>I am writing this post in <a href="http://www.sublimetext.com/2">Sublime Text</a>, my current favorite plain text editor. I have nothing but white letters against a dark grey background, and that&#8217;s the way I like it.</p>

<p>Most documents and data we produce could be read out loud to another human, even if it took a long time. This means they could also be stored as plain text. So why bring in extra layers of complications? Why send a one-page PDF in an email, saying &#8220;Please see attached invitation&#8221;? Why save simple writings in a proprietary data format pushed by Microsoft? Why store data in a not very efficient binary format pushed by Stata?</p>

<!-- more -->


<p>Machines, you might say. Some of these documents will be read by machines rather than humans. Surely, if your data has some machine-readable structure, you want to preserve it. You would like the computer to render the invitation just as beautifully on the reader&#8217;s screen as it did on yours. You would like your bullet items to be editable as such by your coauthors. And you would like them to load the same variables in the same order as you have in your Stata dataset.</p>

<p>There are plenty of ways to represent structure in plain text. This way, both humans and machines will be able to read your document. See, for example, data containing a few months of the S&amp;P 500 index represented in comma separated values versus Stata&#8217;s proprietary <code>.dta</code> format. They hold the exact same information. Yet, the first is readable on more machines (including those that don&#8217;t have Stata) and by more humans.</p>

<p><img src="http://momentofmethods.com/images/posts/csv.png"></p>

<p><img src="http://momentofmethods.com/images/posts/dta.png"></p>

<p>More complicated data structures can also be represented in plain text. <a href="http://en.wikipedia.org/wiki/JSON">JSON</a> has become the de facto standard for web applications to transmit their data. (Forget XML. Since when is it considered human readable?)</p>

<p><img src="http://momentofmethods.com/images/posts/xml.png"></p>

<p>My personal is favorite is <a href="http://en.wikipedia.org/wiki/Yaml">YAML</a>. It is the same concept as JSON, but more reader friendly. The first two datapoints of <code>sp500.csv</code> in JSON:</p>

<pre><code>[{"date": "Jan 2000", "price": "1394.46"}, {"date": "Feb 2000", "price": "1366.42"}]
</code></pre>

<p>The same in YAML:</p>

<pre><code>- date: Jan 2000
  price: "1394.46"
- date: Feb 2000
  price: "1366.42"
</code></pre>

<p>If you decide to do most of your work in plain text, you will need a good editor. One that can, at the very least:</p>

<ul>
<li>automatically wrap long lines (I am amazed that some editors don&#8217;t do this)</li>
<li>highlight the syntax of the programming or markup languages (such as JSON and YAML above) that you use the most</li>
<li>indent nicely without your having to press <code>TAB</code> all the time</li>
<li>support different character encodings, including the most widely used Unicode encoding, UTF-8.</li>
</ul>


<p>I am happy with Sublime Text. I also like <a href="http://www.iawriter.com/">iA Writer</a> for Mac and iOs. On Windows, I experimented with <a href="http://notepad-plus-plus.org/">Notepad++</a>. (The original Windows Notepad is so deficient that it does not satisfy <em>any</em> of the four requirements above.)</p>

<p>What editor do you use? What limitations do you think plain text has over binary file formats?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forget Fortran]]></title>
    <link href="http://momentofmethods.com/blog/2012/10/05/forget-fortran/"/>
    <updated>2012-10-05T15:14:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/10/05/forget-fortran</id>
    <content type="html"><![CDATA[<p>Climbers strive for speed in the mountains not because they want to minimize the time spent in danger zones. How do we make our programs run faster? What are the danger zones of programming?</p>

<!-- more -->


<p>I want to write fast programs so that I can iterate more often. I do something, let it run, make some changes, let it run again, and so on. This is impossible if your program takes two weeks to complete.</p>

<p>Your first instinct might be to go out to learn a fast programming language like C or Fortran. For that matter, pretty much anything is faster than Matlab or NumPy. If you are already comfortable with one of these low-level languages, good for you. But I think fast iteration is better served by a more human friendly, more high-level language. If my code takes several hours to debug each time, I have not gained much from its faster execution.</p>

<p>An alternative approach is to fine-tune your existing code to squeeze out the maximum speed. Take, for example, <a href="http://statsmodels.sourceforge.net/">Statsmodels</a>, a Python library for estimating statistical models. Because most time is spent moving data to and from memory, the author has rewritten even the basic functions to minimize these data movements.</p>

<p>To estimate bicubic kernel functions, for example, one needs to raise all elements of a vector to the the cube. Here is how Statsmodel <a href="https://github.com/statsmodels/statsmodels/blob/master/statsmodels/nonparametric/smoothers_lowess.py">does it</a>:</p>

<pre><code>def _lowess_mycube(t):
    """
    Fast matrix cube

    Parameters
    ----------
    t : ndarray
        Array that is cubed, elementwise and in-place

    Returns
    -------
    Nothing

    """
    #t **= 3
    t2 = t*t
    t *= t2
</code></pre>

<p>You do two multiplications in place and one copying of the vector. Clever. But is this really necessary? Should I write a separate cube function each time it is needed? That would be <a href="http://momentofmethods.com/blog/2012/09/26/dont-repeat-yourself-ever/">so wrong</a>. Such a program is prone for errors, which is what I wanted to avoid in the first place.</p>

<p>What then? Personally, I prefer my program clean rather than fast. An approach that I am experimenting with is parallel or distributed programming. This maintains the clean nature of the code as each thread only needs to deal with its own task. It also helps that distributed execution pretty much scales linearly. I can run my code on 640 cores over at <a href="http://picloud.com">PiCloud</a> with no more effort than doing it on my quad-core computer. <a href="https://github.com/korenmiklos/Technological-Diversification-AER/tree/master/quantitative_assessment">This is what I did for a recent paper</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Don't Repeat Yourself. Ever.]]></title>
    <link href="http://momentofmethods.com/blog/2012/09/26/dont-repeat-yourself-ever/"/>
    <updated>2012-09-26T15:32:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/09/26/dont-repeat-yourself-ever</id>
    <content type="html"><![CDATA[<p>Like most economists, I started coding by accident, so I never had any training. The closest I came to a formal training was reading <a href="http://pragprog.com/book/tpp/the-pragmatic-programmer">The Pragmatic Programmer</a>. It is a book you should read cover to cover, <em>twice</em>. It doesn&#8217;t tell you much about how to write a loop in C, but it gives you a lot of useful tricks about how to become better at the things programmers do every day. The focus is on you as a human, not the computer.</p>

<p>I guess I should have learned to be pragmatic about this, but there is one advice from the book that I treat as <em>dogma</em>.</p>

<blockquote><p>Don&#8217;t Repeat Yourself: Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.</p></blockquote>

<!-- more -->


<p>The goal of the <a href="http://en.wikipedia.org/wiki/Don't_repeat_yourself">DRY principle</a> is not to save you some typing. In fact, sticking to DRY may sometimes make your code longer rather than shorter. The goal is to minimize the risk of human error. If I store the same information in two different places, they will surely fall out of sync sometime soon. At some point I will update one but not the other. Then I will <em>believe</em> I have the same information in the two places when in fact I have something else.</p>

<p>To give you an example, I use the <em>Hungarian Customs Statistics</em> dataset in several of my <a href="http://miklos.koren.hu/view/kmwprs/">papers</a>. I keep learning more about the data and do various cleaning steps as I go along. If I did this separately for each paper, there would be no single, unambiguous meaning of <em>the</em> Customs Statistics. Given that it takes years to complete a paper from idea to publication, I would almost certainly mix up the different version.</p>

<p>Instead, I store oft-used datasets separately from projects in a datastore. All the data-cleaning codes reside with the data in this datastore, e.g., at <code>datastore/customs/data</code> and <code>datastore/customs/code</code>. (See my <a href="http://momentofmethods.com/blog/2012/09/19/cultivate-your-tree/">previous post</a> on folder structure.) Each of my projects, and each of my coauthors on these projects can then refer to the datastore.</p>

<p>At the very least, DRY tells you to use constants to parametrize your program. Suppose my Stata code keeps loading files from the folder <code>/media/home/share/datastore/customs</code>. It would make sense to define the constant <code>customs_folder</code> and refer to that later on. This simple trick could have saved me hours of debugging. (Aside: Stata is really lousy about variables. There are no string variables, only <a href="http://www.stata.com/help.cgi?macro">macros</a>. So to set the &#8220;constant,&#8221; you need to define a local macro as <code>local customs_folder /media/home/share/datastore/customs</code>. If you haven&#8217;t done it yet, go ahead and read up on Stata macros.)</p>

<p>As a more knife-edge example, compare the following Stata code</p>

<pre><code>areg lnwage treatment age, a(firmid) cluster(firmid)
areg lnwage treatment schooling, a(firmid) cluster(firmid)
</code></pre>

<p>to</p>

<pre><code>foreach control of var age schooling {
    areg lnwage treatment `control', a(firmid) cluster(firmid)
}
</code></pre>

<p>They do the same: regress wages on a treatment variable using as control either age or schooling. But what if a referee suggests I should cluster my standard errors by city rather than firm? In the second case, I only have to rewrite <code>cluster(firmid)</code> to <code>cluster(cityid)</code> once and I can be sure that all my speficications use the same clustering.</p>

<p>This is probably taking DRY to the extreme. The second code is not shorter or easier to read than the first. Still, you should treat DRY as dogma. You will be tempted. Your fingers will be itching to press <code>Ctrl-C</code>, <code>Ctrl-V</code>. Don&#8217;t go there. If it is the same information, it should only be said once. Your future self six months down the road will be thankful.</p>

<p>How far are you taking DRY? Do you have useful tricks to minimize errors from repetition?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cultivate your tree]]></title>
    <link href="http://momentofmethods.com/blog/2012/09/19/cultivate-your-tree/"/>
    <updated>2012-09-19T17:27:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/09/19/cultivate-your-tree</id>
    <content type="html"><![CDATA[<p>The thing I probably hated the most as a Windows user was folder names like <code>C:\Documents and Settings\koren\My Documents\My Dropbox</code>. This was a pain to use even with the small scripts that economists write (such as <a href="http://stata.com/">Stata</a> <code>do</code> files). I understand Microsoft wants me to point and click, but why make it harder to spell my folder names? Compare it to <code>/home/koren/Dropbox</code>.</p>

<p>This is not a minor nuisance, since by effectively prohibiting me to type my folder names, Microsoft made me sloppier in maintaining a nice tree structure. It took me a while to realize that the <a href="http://en.wikipedia.org/wiki/Unix">tried and tested</a> tree structure is, at least currently, the most efficient way of storing and retrieving my documents and other files.</p>

<!-- more -->


<p><img class="center" src="http://farm1.staticflickr.com/109/294927196_d501c5cf97.jpg"></p>

<p>In Unix-like systems, every file is part of a single tree, starting at <code>/</code>. Trees are great because you can traverse them easily. I almost never have to search for a file. I am quite certain about where to find <code>~/Dropbox/projects/machines/text/slides90.tex</code> or <code>~/Dropbox/courses/trade/lectures/figures/food_trade.pdf</code>. In fact, if you maintain a deep-enough tree structure, you will find each file with at most <code>O(log N)</code> clicks, where <code>N</code> is the number of files.</p>

<p>Also, subtrees let you hold related stuff together. Of course, it is up to you to decide what is related. To me, <code>machines/code</code> and <code>machines/data</code> sound more related than <code>code/machines</code> and <code>code/spillovers</code>. So a typical project folder looks like::</p>

<pre><code>machines
    code
    data
        customs
        wages
    text
        figures
        tables
    literature
</code></pre>

<p>This way it is easy to share a project folder with a coauthor, as codes, text and data all reside there. As I will discuss later this week, one concern is that if you would like to reuse code or data in another project, it makes no sense to keep  replicas in different places.</p>

<p>A few suggestions to grow a healthier tree:</p>

<ol>
<li>Use forward slashes (<code>/</code>) in paths, even on Windows. Windows will not complain, and your Linux/Mac coauthors will thank you.</li>
<li>Use relative paths. For example, from scripts residing in <code>projects/machines/code</code> I can reach data residing in <code>projects/machines/data</code> by simply referring to <code>../data</code>. This way I don&#8217;t need to know where my coauthor has placed her project folder.</li>
<li>Avoid spaces and accents. I&#8217;m all for expressive filenames, but you don&#8217;t want to risk compatibility across platforms. A friend of mine once created an <a href="http://en.wikipedia.org/wiki/ArchiCAD">ArchiCAD</a> file called <code>szőlőfeldolgozó üzem.pln</code> for a class project. His project got almost killed by different version of Windows at school. Underscore_is_perfectly_suitable to replace spaces, although these days dashes-are-more-trendy.</li>
<li>Separate files by topics and function, not by date and author. I have a fairly good idea what <code>projects/machines/code</code> vs <code>projects/machines/data</code> hold, but try guessing what is inside <code>june2012version/adam</code>. Use <a href="http://momentofmethods.com/blog/2012/09/10/dropbox-is-not-enough/">version control</a> for sharing and storing history.</li>
</ol>


<p>Where do you store your project files? How do you organize them?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SparkleShare for moving large data]]></title>
    <link href="http://momentofmethods.com/blog/2012/09/15/sparkleshare-for-moving-large-data/"/>
    <updated>2012-09-15T14:16:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/09/15/sparkleshare-for-moving-large-data</id>
    <content type="html"><![CDATA[<p>I sometimes have to move large amounts of data. At least large by the standards of an economist turned hacker. For example, the shapefiles and data from the <a href="http://www.census.gov/econ/cbp/">County and ZIP-Code Business Patterns</a> that I use in my paper &#8220;Cattle, Steaks and Restaurants&#8221; take up 2 GB. In my <a href="http://momentofmethods.com/blog/2012/09/10/dropbox-is-not-enough/">previous post</a>, I said that Dropbox is not suitable for storing, synchronizing and sharing data of this size, especially if you are on the wrong side of the Atlantic.</p>

<!-- more -->


<p>Dropbox <a href="https://www.dropbox.com/help/7/en">stores all our files</a> on Amazon S3 servers in the U.S. Even though Amazon has servers in Ireland, you cannot tell Dropbox to use those. This is going to slow you down if you are in Europe. In addition, some of the data I use are proprietary and I simply cannot put them on a server outside my control.</p>

<p><a href="http://sparkleshare.org/">SparkleShare</a> to the rescue. It is an open source file sharing client, which works much like Dropbox: whenever you add or change files in a special folder, they are uploaded to the server. The beauty of SparkleShare is that it uses Git in the background. All it needs is a Git repository to synchronize with. You can have it on your own server to minimize data travel time and to maximize security.</p>

<p>To give you an idea about the speed gains, I have conducted a simple non-scientific test. To test upload speed, I have synched an 86.3MB binary file from my home computer to the Dropbox/SparkleShare server. My SparkleShare server is hosted by <a href="http://www.webfaction.com/">Webfaction</a> in Amsterdam. In a very scientific manner, I simply measured how long it took until the Dropbox/SparkleShare icon stopped spinning, indicating that file transfer has completed.</p>

<p>To measure download, I got a different, 59.4 MB binary file to the Dropbox/SparkleShare servers. I used web upload for Dropbox and measured the time it took after the file appeared on the server to it becoming available on my computer.
For SparkleShare, just added the file to the Git repository on the server and measured the time it took <code>git pull</code> to complete.</p>

<p>I report the results as minutes per GB, so smaller numbers are better. I rescaled things to GB so that the numbers are more representative of working with large data.</p>

<script type="text/javascript" src="http://momentofmethods.com//ajax.googleapis.com/ajax/static/modules/gviz/1.0/chart.js"> {"dataSourceUrl":"//docs.google.com/spreadsheet/tq?key=0AhJS2rfBAT8JdGhOWWRDaFhlVGI0XzNhZ1E3NmJIVFE&transpose=1&headers=1&range=C12%3AE14&gid=0&pub=1","options":{"titleTextStyle":{"bold":true,"color":"#000","fontSize":16},"vAxes":[{"useFormatFromData":true,"minValue":null,"viewWindowMode":null,"viewWindow":null,"maxValue":null},{"useFormatFromData":true}],"series":{"0":{"color":"#6fa8dc"},"1":{"color":"#e69138"}},"title":"","booleanRole":"certainty","animation":{"duration":0},"domainAxis":{"direction":1},"legend":"top","hAxis":{"useFormatFromData":true,"minValue":null,"viewWindowMode":"pretty","logScale":false,"viewWindow":{"min":null,"max":null},"maxValue":null},"isStacked":false,"width":600,"height":371},"state":{},"view":{},"chartType":"BarChart","chartName":"Chart 1"} </script>


<p>It takes 39 minutes to upload a GB to Dropbox over my cable connection from home. Excruciatingly slow. SparkleShare is about twice as fast. The real difference, however, is between download speeds. While Dropbox took 27 minutes per GB, SparkleShare took less than 2. An order of magnitude faster!</p>

<p>This is why I use SparkleShare (or, with nerdy coauthors, simply Git) to share large datafiles. What solutions do you use for this problem? What is your experience with Dropbox and SparkleShare?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dropbox is not enough]]></title>
    <link href="http://momentofmethods.com/blog/2012/09/10/dropbox-is-not-enough/"/>
    <updated>2012-09-10T15:58:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/09/10/dropbox-is-not-enough</id>
    <content type="html"><![CDATA[<p>I love Dropbox. It has saved me from a nervous breakdown several times. I am working directly in my Dropbox folder, and all my computers are automatically in sync. I have not seen a pendrive in ages. I also have <a href="https://www.dropbox.com/help/113/en">Packrat</a> enabled, which came handy several times in recovering a long-lost file. All my coauthors are on Dropbox, and it is our default tool for sharing files. So, if you still do not have a Dropbox account, by all means, sign up now.</p>

<p>There are two aspects, however, where Dropbox falls short. The first is version control. Sure, Packrat keeps all past versions, but good luck finding the right version of your file among 48 revisions. The second is data storage &#8211; somewhere in the jungles of Amazon S3. With large and sensitive datasets you might want to have more control over where you store your data. Let me write about the first of these today.</p>

<!-- more -->


<p><img src="http://momentofmethods.com/images/posts/packrat.png"></p>

<p>If you are working with others and want to follow <em>who</em> changed <em>what</em>, you need proper version control. The two most popular version control tools I have experience with are <a href="http://subversion.tigris.org">Subversion</a> and <a href="http://git-scm.com/">Git</a>. Both are suitable for storing and sharing past versions of your files with helpful messages attached to them. Both are open source and come with a number of user-friendly clients.</p>

<p><a href="http://www.brandonsavage.net/git-versus-subversion-a-reconsideration/">Some believed</a> that Git is more difficult to learn than Subversion. <em>After</em> you have used Subversion, Git may take some getting used to, because it uses a different concept. However, if you never used either of these, go with Git. It is much easier to adopt.</p>

<p>You should think of Git as a tool to create archeological layers of the past versions of your files and folders. I say archeological layers, because all your past data stays <em>in place</em>, underneath your current version. (In practice, they are stored in a subfolder named <code>.git</code>.) There is no need to set up a server to host your past data. This makes it easier to get started (no funky setup) and faster to save newer and newer versions (no network traffic). The point of version control is to control versions, and Git makes it as easy as possible.</p>

<p><img src="http://momentofmethods.com/images/posts/git-tower.png"></p>

<p>As an example, look at the history of the same file (courtesy of the beautiful Git client for Mac, <a href="http://www.git-tower.com/index.html">Tower</a>). I have attached comments to each version and I can quickly compare what actually changed. It takes some discipline, as I have to explicitly drag-and-drop the files whenever I want to save a new version and I also have to attach a comment. But this is still faster than emailing your coauthor to let them know what changed in the Dropbox folder.</p>

<p>Of course, with Git (as well as Subversion) you can also share your folder with others. I say it as an afterthought because Dropbox already easily takes care of the sharing part. If you keep your <code>.git</code> folder inside your Dropbox folder, then not only the current version, but all past versions are also shared across computers. This is not the official way to do it, because Git and Dropbox may get tangled up, especially if you lose network connection and Dropbox cannot refresh for a long time. For me, it has worked fine. If you want to put your files on a server instead, <a href="https://github.com/">GitHub</a> is a popular choice.</p>

<p>I hope that by now you are excited to try Git. Head over to its official (and free) <a href="http://git-scm.com/book">book</a> to learn how it actually works.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What I learned from software developers]]></title>
    <link href="http://momentofmethods.com/blog/2012/09/07/what-i-learned-from-software-developers/"/>
    <updated>2012-09-07T17:19:00+02:00</updated>
    <id>http://momentofmethods.com/blog/2012/09/07/what-i-learned-from-software-developers</id>
    <content type="html"><![CDATA[<p>Software developers are like us on many levels. They build abstract models to solve concrete problems. They write lots of code. They work in teams. They love to show off their work to the community.</p>

<!-- more -->


<p>But first, and foremost, they love to learn new stuff to become better at what they do. The sheer number of <a href="http://en.wikipedia.org/wiki/List_of_programming_languages_by_category">programming languages</a> out there is amazing. So, the real defining fearure of nerds is not that they don&#8217;t have a life. It&#8217;s that they have an insatiable hunger for knowledge and up-to-date skills. Sounds like the way academics like to describe themselves. Nerds are us.</p>

<p>I learned from software developers to never stop developing my craft. Mind you, there is a fine line between learning useful new tools and browsing the web to procrastinate. But if you are still using Word to write your papers, email to send your files, an HTML editor and FTP to update your website, an old EViews to run your regressions, or unwieldy Matlab codes to simulate your model, you should ask yourself whether it&#8217;s because these are the best tools for you (might be) or because you grew lazy to learn something new (more likely).</p>

<p>Software developers have taught me how to</p>

<ul>
<li>collaborate more effectively (use version control),</li>
<li>build useful abstractions (how to think about data),</li>
<li>write better code (optimized for humans, not computers).</li>
</ul>


<p>I will write about each of these in more detail.</p>
]]></content>
  </entry>
  
</feed>
